{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_LSTM_Model_Language_Translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roht20/Portfolio/blob/master/Seq2Seq_LSTM_Model_Language_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tvqWOP1a95-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Seq2Seq_LSTM_Language_Translation**"
      ]
    },
    {
      "metadata": {
        "id": "wuG0AnFK-LMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YjBRcKo-Qs9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Prepare data\n",
        "Data was downloaded from http://www.manythings.org/anki/\n",
        "\n",
        "1.1 Data has sentence pairs each English word has a corresponding Hindi word"
      ]
    },
    {
      "metadata": {
        "id": "iNyXJrnW-Nb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/hin-eng.zip --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IesqNrtQ-XNc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing the necessary libraries**"
      ]
    },
    {
      "metadata": {
        "id": "efwUG5nj-Ubg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Epd0kMFt-cf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zf = zipfile.ZipFile('hin-eng.zip', 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZuQ8Kv1-fKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = ''\n",
        "with zf.open('hin.txt') as readfile:\n",
        "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
        "    data += line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fB-LlFT-hff",
        "colab_type": "code",
        "outputId": "c7d8867b-7c30-4bee-9cc6-18509d6e12a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data[0:50]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wow!\\tवाह!\\nHelp!\\tबचाओ!\\nJump.\\tउछलो.\\nJump.\\tकूदो.\\nJump'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "7bKIt7q7-jn6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data =  data.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CkBeYI-Y-8Pb",
        "colab_type": "code",
        "outputId": "a4af7ec9-4972-4cca-8b10-eba0921d8edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "UNRnxVzX_D0a",
        "colab_type": "code",
        "outputId": "eeb99e06-7b46-4fea-8a23-416301f2b703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "data[100:105]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I can't move.\\tमैं हिल नहीं सकता।\",\n",
              " \"I don't know.\\tमुझे नहीं पता।\",\n",
              " \"I don't know.\\tमुझे नहीं मालूम।\",\n",
              " 'I have a car.\\tमेरे पास एक गाड़ी है।',\n",
              " 'I have a dog.\\tमेरे पास एक कुत्ता है।']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "a0hQattL_PsT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Review the data\n",
        "\n",
        "1.2 Separate out Encoder and Decoder input data**"
      ]
    },
    {
      "metadata": {
        "id": "nsPnXl8r_Gs1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_text = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nc5HKcQA_Syv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_text = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JxCJ21Gx_Ujn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for line in data:\n",
        "    try:\n",
        "        in_txt, out_txt = line.split('\\t')\n",
        "        encoder_text.append(in_txt)\n",
        "        \n",
        "        # Add tab '<start>' as 'start sequence in target\n",
        "        # And '<end>' as End\n",
        "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
        "    except:\n",
        "        pass #ignore data which goes into error "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JOhecEQH_YP2",
        "colab_type": "code",
        "outputId": "04b50520-9895-4c28-8064-df1eb25a0c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_text[100:105]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> मैं हिल नहीं सकता। <end>',\n",
              " '<start> मुझे नहीं पता। <end>',\n",
              " '<start> मुझे नहीं मालूम। <end>',\n",
              " '<start> मेरे पास एक गाड़ी है। <end>',\n",
              " '<start> मेरे पास एक कुत्ता है। <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "6WZDLMdu_aT_",
        "colab_type": "code",
        "outputId": "419ce58f-587d-4776-8df7-03fc9cb36a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_text[100:105]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I can't move.\",\n",
              " \"I don't know.\",\n",
              " \"I don't know.\",\n",
              " 'I have a car.',\n",
              " 'I have a dog.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "FAFnNA-6_e0y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.3 Building Sequences for Encoder and Decoder Input**"
      ]
    },
    {
      "metadata": {
        "id": "xSiZf589_kvm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing the Tokenzier from the Keras library**"
      ]
    },
    {
      "metadata": {
        "id": "goEgeh_5_cQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R35Hn2fJ_jjh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_t = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uiAeD2wn_tDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_t.fit_on_texts(encoder_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHFayELq_vd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_seq = encoder_t.texts_to_sequences(encoder_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6u2CVEO_yYz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5a5xRUMe_0oR",
        "colab_type": "code",
        "outputId": "65f361a9-d2ee-42b9-8227-c84fd332cf00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "BNJdck4B_3tr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(encoder_t.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-v8gEJ91_6zU",
        "colab_type": "code",
        "outputId": "d0f24159-76c8-4bb3-e260-8e06be21fffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_vocab_size"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "ERG1Xc26_8jY",
        "colab_type": "code",
        "outputId": "8a3d43e9-e172-4c9b-ea97-e7bbab771bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_text[100:105]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I can't move.\",\n",
              " \"I don't know.\",\n",
              " \"I don't know.\",\n",
              " 'I have a car.',\n",
              " 'I have a dog.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "5Ntt0nJ6_-iq",
        "colab_type": "code",
        "outputId": "de648ad0-370b-486d-da3d-d4914a156852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_seq[100:105]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 68, 406], [2, 28, 43], [2, 28, 43], [2, 12, 6, 100], [2, 12, 6, 131]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "rZw5mwkwAFhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Decoder tokenizer**"
      ]
    },
    {
      "metadata": {
        "id": "f4flQzIqAB8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_t = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwbNHOeGALJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_t.fit_on_texts(decoder_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1enRe77AMqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_seq = decoder_t.texts_to_sequences(decoder_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqs6fyYCAOV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpPxvStuAQOy",
        "colab_type": "code",
        "outputId": "f9e6d20f-0c8a-495c-ca52-50020d3f4cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "gwDy9DBEARxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_vocab_size = len(decoder_t.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6EhSAerATgX",
        "colab_type": "code",
        "outputId": "4d468383-8917-44be-853e-0e3768a1d479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_vocab_size"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "TcuV0hDrAVyV",
        "colab_type": "code",
        "outputId": "db4817e1-732c-49a0-c488-3fa23476c762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_text[100:105]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> मैं हिल नहीं सकता। <end>',\n",
              " '<start> मुझे नहीं पता। <end>',\n",
              " '<start> मुझे नहीं मालूम। <end>',\n",
              " '<start> मेरे पास एक गाड़ी है। <end>',\n",
              " '<start> मेरे पास एक कुत्ता है। <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "YR-ZIvOBAYET",
        "colab_type": "code",
        "outputId": "5a354173-194f-4cd0-fd7e-d5410748086b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_seq[100:105]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 6, 1498, 5, 162, 2],\n",
              " [1, 12, 5, 630, 2],\n",
              " [1, 12, 5, 1499, 2],\n",
              " [1, 28, 40, 20, 106, 3, 2],\n",
              " [1, 28, 40, 20, 208, 3, 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "z6k-h0dyAcoz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Padding Sequences**"
      ]
    },
    {
      "metadata": {
        "id": "6jJfus9dAaOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ywOw_0NAgap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = pad_sequences(encoder_seq, maxlen=max_encoder_seq_length, padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7dWWAtLAjQj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_input_data = pad_sequences(decoder_seq, maxlen=max_decoder_seq_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3b_hGWa0Al3Z",
        "colab_type": "code",
        "outputId": "f666a6d5-3f30-4a1f-99ef-a73bdcf27e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2866, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "x4xAIVXxAn2Z",
        "colab_type": "code",
        "outputId": "242270ef-449e-42b0-a3e2-0976353d4e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_input_data.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2866, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "6PGUPo3RA1Od",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Integer to Word converter for Decoder data**"
      ]
    },
    {
      "metadata": {
        "id": "Lk2OB3guAsLI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#decoder_t.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-EvY87H8A4E1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDmD-IGnA51P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#int_to_word_decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xv3HUa1BmpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.5 Building Decoder Output data**"
      ]
    },
    {
      "metadata": {
        "id": "CeM7SthGBe7P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZ8WitXJBspa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(decoder_input_data.shape[0]):\n",
        "    for j in range(1,decoder_input_data.shape[1]):\n",
        "        decoder_target_data[i][j-1] = decoder_input_data[i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z00IF8iyBvQk",
        "colab_type": "code",
        "outputId": "85f7c14a-2a7d-4809-b440-1d7b23f1067f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_input_data[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1, 767,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "Kqb7VyfJBxXZ",
        "colab_type": "code",
        "outputId": "111f4fb8-3b97-497d-fae5-55f105f65cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_target_data[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([767.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "VCc1wOWsB2qy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**\n",
        "Converting target data in one hot vector**"
      ]
    },
    {
      "metadata": {
        "id": "bAIC2UvrBzY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.utils import  to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3LBcUT4kB5wR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], \n",
        "                                   decoder_input_data.shape[1],\n",
        "                                   len(decoder_t.word_index)+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgJjnb8lB7n2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(decoder_target_data.shape[0]):\n",
        "    for j in range(decoder_target_data.shape[1]):\n",
        "        decoder_target_one_hot[i][j] = to_categorical(decoder_target_data[i][j],\n",
        "                                                      num_classes=len(\n",
        "                                                          decoder_t.word_index)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DdTDj7eB-Qx",
        "colab_type": "code",
        "outputId": "9c1d76b5-8445-476b-d214-309f0fe4b399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "decoder_target_one_hot.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2866, 27, 3010)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "FKH29quzCCn2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Building the Training Model\n",
        "**"
      ]
    },
    {
      "metadata": {
        "id": "MiAksQDhCApU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIy0ZpqMCLHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**\n",
        "Define config parameters**"
      ]
    },
    {
      "metadata": {
        "id": "puBzcMEcCITa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_embedding_size = 50\n",
        "decoder_embedding_size = 50\n",
        "rnn_units = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qR7RjqB5CQuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.1 Building Encoder layers**"
      ]
    },
    {
      "metadata": {
        "id": "0PjUDoXCCOFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2ceArSzCT7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_embedding = Embedding(encoder_vocab_size+1, encoder_embedding_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OBxWusJCWZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_embedding_output = encoder_embedding(encoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0Op4EXDCY6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x, state_h, state_c = LSTM(rnn_units,return_state=True)(encoder_embedding_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HXVHWhJECbWr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kbmbDxe4Cf0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.2 Building Decoder layers**"
      ]
    },
    {
      "metadata": {
        "id": "grEx8Ua4CdFS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(None,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFTjHYtPCklR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_embedding = Embedding(decoder_vocab_size + 1, decoder_embedding_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVG7RvZUCnEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_embedding_output = decoder_embedding(decoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1FtXvnnCo5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_rnn = LSTM(rnn_units, return_sequences=True, return_state=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6_WvgQcCqsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize initial state with encoder_states\n",
        "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
        "x,_,_ = decoder_rnn(decoder_embedding_output, initial_state=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6nav0udWCtaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_dense = Dense(decoder_vocab_size + 1, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0gLFOURCvXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_outputs = decoder_dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7dFbZQeCzhd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.3 Building Model using both Encoder and Decoder layers\n",
        "**"
      ]
    },
    {
      "metadata": {
        "id": "N525qHMlCxZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htRUCVBQC3TA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvHtkuKhC498",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OqN1Uj1C9gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Training the model**"
      ]
    },
    {
      "metadata": {
        "id": "FZrgw4IvC6tr",
        "colab_type": "code",
        "outputId": "77cfd86b-2cf9-4442-aaf4-ab9626e048c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6851
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n",
        "          batch_size=100,\n",
        "          epochs=200,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2292 samples, validate on 574 samples\n",
            "Epoch 1/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.1089 - val_loss: 2.6013\n",
            "Epoch 2/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0992 - val_loss: 2.6063\n",
            "Epoch 3/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0904 - val_loss: 2.6232\n",
            "Epoch 4/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0825 - val_loss: 2.6307\n",
            "Epoch 5/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0737 - val_loss: 2.6160\n",
            "Epoch 6/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0652 - val_loss: 2.6130\n",
            "Epoch 7/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0566 - val_loss: 2.6145\n",
            "Epoch 8/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0478 - val_loss: 2.6244\n",
            "Epoch 9/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0386 - val_loss: 2.6225\n",
            "Epoch 10/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0297 - val_loss: 2.6349\n",
            "Epoch 11/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0204 - val_loss: 2.6311\n",
            "Epoch 12/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0115 - val_loss: 2.6443\n",
            "Epoch 13/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 1.0018 - val_loss: 2.6374\n",
            "Epoch 14/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9922 - val_loss: 2.6396\n",
            "Epoch 15/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9827 - val_loss: 2.6423\n",
            "Epoch 16/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9731 - val_loss: 2.6422\n",
            "Epoch 17/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9639 - val_loss: 2.6455\n",
            "Epoch 18/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9544 - val_loss: 2.6670\n",
            "Epoch 19/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9445 - val_loss: 2.6631\n",
            "Epoch 20/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9349 - val_loss: 2.6639\n",
            "Epoch 21/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9250 - val_loss: 2.6788\n",
            "Epoch 22/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9163 - val_loss: 2.6791\n",
            "Epoch 23/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.9071 - val_loss: 2.6711\n",
            "Epoch 24/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8970 - val_loss: 2.6722\n",
            "Epoch 25/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8869 - val_loss: 2.6988\n",
            "Epoch 26/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8768 - val_loss: 2.6890\n",
            "Epoch 27/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8676 - val_loss: 2.7064\n",
            "Epoch 28/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8578 - val_loss: 2.7107\n",
            "Epoch 29/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8480 - val_loss: 2.7109\n",
            "Epoch 30/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8373 - val_loss: 2.7288\n",
            "Epoch 31/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8271 - val_loss: 2.7295\n",
            "Epoch 32/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8170 - val_loss: 2.7294\n",
            "Epoch 33/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.8076 - val_loss: 2.7487\n",
            "Epoch 34/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7988 - val_loss: 2.7464\n",
            "Epoch 35/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7887 - val_loss: 2.7242\n",
            "Epoch 36/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7778 - val_loss: 2.7452\n",
            "Epoch 37/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7670 - val_loss: 2.7494\n",
            "Epoch 38/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7567 - val_loss: 2.7409\n",
            "Epoch 39/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7474 - val_loss: 2.7629\n",
            "Epoch 40/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7375 - val_loss: 2.7693\n",
            "Epoch 41/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7270 - val_loss: 2.7647\n",
            "Epoch 42/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7170 - val_loss: 2.7632\n",
            "Epoch 43/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.7074 - val_loss: 2.7608\n",
            "Epoch 44/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6977 - val_loss: 2.7811\n",
            "Epoch 45/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6873 - val_loss: 2.7835\n",
            "Epoch 46/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6780 - val_loss: 2.7972\n",
            "Epoch 47/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6680 - val_loss: 2.7958\n",
            "Epoch 48/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6572 - val_loss: 2.7997\n",
            "Epoch 49/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6478 - val_loss: 2.8159\n",
            "Epoch 50/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6382 - val_loss: 2.8129\n",
            "Epoch 51/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6285 - val_loss: 2.8115\n",
            "Epoch 52/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6182 - val_loss: 2.8334\n",
            "Epoch 53/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.6092 - val_loss: 2.8272\n",
            "Epoch 54/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5998 - val_loss: 2.8474\n",
            "Epoch 55/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5903 - val_loss: 2.8443\n",
            "Epoch 56/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5815 - val_loss: 2.8540\n",
            "Epoch 57/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5726 - val_loss: 2.8812\n",
            "Epoch 58/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5650 - val_loss: 2.8632\n",
            "Epoch 59/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5560 - val_loss: 2.8687\n",
            "Epoch 60/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5459 - val_loss: 2.8657\n",
            "Epoch 61/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5371 - val_loss: 2.8717\n",
            "Epoch 62/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5299 - val_loss: 2.8769\n",
            "Epoch 63/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5214 - val_loss: 2.8836\n",
            "Epoch 64/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5123 - val_loss: 2.8947\n",
            "Epoch 65/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.5032 - val_loss: 2.8991\n",
            "Epoch 66/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4945 - val_loss: 2.9040\n",
            "Epoch 67/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4862 - val_loss: 2.9132\n",
            "Epoch 68/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4791 - val_loss: 2.9156\n",
            "Epoch 69/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4710 - val_loss: 2.9132\n",
            "Epoch 70/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4634 - val_loss: 2.9322\n",
            "Epoch 71/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4558 - val_loss: 2.9291\n",
            "Epoch 72/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4483 - val_loss: 2.9498\n",
            "Epoch 73/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4406 - val_loss: 2.9495\n",
            "Epoch 74/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4344 - val_loss: 2.9537\n",
            "Epoch 75/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4282 - val_loss: 2.9478\n",
            "Epoch 76/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4203 - val_loss: 2.9704\n",
            "Epoch 77/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4127 - val_loss: 2.9820\n",
            "Epoch 78/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.4066 - val_loss: 2.9764\n",
            "Epoch 79/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3992 - val_loss: 2.9861\n",
            "Epoch 80/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3925 - val_loss: 2.9894\n",
            "Epoch 81/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3858 - val_loss: 2.9918\n",
            "Epoch 82/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3787 - val_loss: 2.9992\n",
            "Epoch 83/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3733 - val_loss: 2.9937\n",
            "Epoch 84/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3672 - val_loss: 3.0103\n",
            "Epoch 85/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3605 - val_loss: 3.0223\n",
            "Epoch 86/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.3538 - val_loss: 3.0202\n",
            "Epoch 87/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3476 - val_loss: 3.0271\n",
            "Epoch 88/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3419 - val_loss: 3.0370\n",
            "Epoch 89/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3370 - val_loss: 3.0454\n",
            "Epoch 90/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3322 - val_loss: 3.0471\n",
            "Epoch 91/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3270 - val_loss: 3.0514\n",
            "Epoch 92/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3217 - val_loss: 3.0593\n",
            "Epoch 93/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3153 - val_loss: 3.0582\n",
            "Epoch 94/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3094 - val_loss: 3.0683\n",
            "Epoch 95/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.3039 - val_loss: 3.0692\n",
            "Epoch 96/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2987 - val_loss: 3.0815\n",
            "Epoch 97/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2947 - val_loss: 3.0872\n",
            "Epoch 98/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2894 - val_loss: 3.0822\n",
            "Epoch 99/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2842 - val_loss: 3.0799\n",
            "Epoch 100/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2799 - val_loss: 3.0968\n",
            "Epoch 101/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2749 - val_loss: 3.1048\n",
            "Epoch 102/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2698 - val_loss: 3.1138\n",
            "Epoch 103/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2654 - val_loss: 3.1239\n",
            "Epoch 104/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2615 - val_loss: 3.1321\n",
            "Epoch 105/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2569 - val_loss: 3.1307\n",
            "Epoch 106/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2529 - val_loss: 3.1313\n",
            "Epoch 107/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2474 - val_loss: 3.1389\n",
            "Epoch 108/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2432 - val_loss: 3.1478\n",
            "Epoch 109/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2403 - val_loss: 3.1462\n",
            "Epoch 110/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2371 - val_loss: 3.1492\n",
            "Epoch 111/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2324 - val_loss: 3.1631\n",
            "Epoch 112/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2282 - val_loss: 3.1487\n",
            "Epoch 113/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2245 - val_loss: 3.1707\n",
            "Epoch 114/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2201 - val_loss: 3.1801\n",
            "Epoch 115/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2161 - val_loss: 3.1717\n",
            "Epoch 116/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2122 - val_loss: 3.1919\n",
            "Epoch 117/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.2089 - val_loss: 3.1894\n",
            "Epoch 118/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.2044 - val_loss: 3.1944\n",
            "Epoch 119/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.2004 - val_loss: 3.1978\n",
            "Epoch 120/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1974 - val_loss: 3.2129\n",
            "Epoch 121/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1933 - val_loss: 3.2173\n",
            "Epoch 122/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1898 - val_loss: 3.2308\n",
            "Epoch 123/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1871 - val_loss: 3.2155\n",
            "Epoch 124/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1839 - val_loss: 3.2402\n",
            "Epoch 125/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1804 - val_loss: 3.2373\n",
            "Epoch 126/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1773 - val_loss: 3.2508\n",
            "Epoch 127/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1736 - val_loss: 3.2450\n",
            "Epoch 128/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1703 - val_loss: 3.2586\n",
            "Epoch 129/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1673 - val_loss: 3.2498\n",
            "Epoch 130/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.1647 - val_loss: 3.2644\n",
            "Epoch 131/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1614 - val_loss: 3.2660\n",
            "Epoch 132/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1580 - val_loss: 3.2744\n",
            "Epoch 133/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1547 - val_loss: 3.2761\n",
            "Epoch 134/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1519 - val_loss: 3.2958\n",
            "Epoch 135/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1490 - val_loss: 3.2986\n",
            "Epoch 136/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1471 - val_loss: 3.2967\n",
            "Epoch 137/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1439 - val_loss: 3.3114\n",
            "Epoch 138/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1410 - val_loss: 3.3169\n",
            "Epoch 139/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1383 - val_loss: 3.3180\n",
            "Epoch 140/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1356 - val_loss: 3.3265\n",
            "Epoch 141/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1330 - val_loss: 3.3346\n",
            "Epoch 142/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1311 - val_loss: 3.3329\n",
            "Epoch 143/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1299 - val_loss: 3.3471\n",
            "Epoch 144/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1281 - val_loss: 3.3514\n",
            "Epoch 145/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1259 - val_loss: 3.3519\n",
            "Epoch 146/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1226 - val_loss: 3.3581\n",
            "Epoch 147/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1194 - val_loss: 3.3579\n",
            "Epoch 148/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1163 - val_loss: 3.3690\n",
            "Epoch 149/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1138 - val_loss: 3.3652\n",
            "Epoch 150/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1117 - val_loss: 3.3822\n",
            "Epoch 151/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1095 - val_loss: 3.3836\n",
            "Epoch 152/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1071 - val_loss: 3.3872\n",
            "Epoch 153/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1049 - val_loss: 3.3993\n",
            "Epoch 154/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1029 - val_loss: 3.4040\n",
            "Epoch 155/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.1011 - val_loss: 3.4105\n",
            "Epoch 156/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0992 - val_loss: 3.4099\n",
            "Epoch 157/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0973 - val_loss: 3.4177\n",
            "Epoch 158/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0960 - val_loss: 3.4169\n",
            "Epoch 159/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0936 - val_loss: 3.4269\n",
            "Epoch 160/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0918 - val_loss: 3.4345\n",
            "Epoch 161/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0902 - val_loss: 3.4415\n",
            "Epoch 162/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0889 - val_loss: 3.4349\n",
            "Epoch 163/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0877 - val_loss: 3.4476\n",
            "Epoch 164/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0854 - val_loss: 3.4603\n",
            "Epoch 165/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0831 - val_loss: 3.4638\n",
            "Epoch 166/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0811 - val_loss: 3.4652\n",
            "Epoch 167/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0795 - val_loss: 3.4766\n",
            "Epoch 168/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0781 - val_loss: 3.4721\n",
            "Epoch 169/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0768 - val_loss: 3.4732\n",
            "Epoch 170/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0751 - val_loss: 3.4818\n",
            "Epoch 171/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0736 - val_loss: 3.4869\n",
            "Epoch 172/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0728 - val_loss: 3.4902\n",
            "Epoch 173/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0714 - val_loss: 3.4963\n",
            "Epoch 174/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0697 - val_loss: 3.5042\n",
            "Epoch 175/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0682 - val_loss: 3.5119\n",
            "Epoch 176/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0665 - val_loss: 3.5140\n",
            "Epoch 177/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0649 - val_loss: 3.5163\n",
            "Epoch 178/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0637 - val_loss: 3.5208\n",
            "Epoch 179/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0627 - val_loss: 3.5332\n",
            "Epoch 180/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0627 - val_loss: 3.5291\n",
            "Epoch 181/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0611 - val_loss: 3.5284\n",
            "Epoch 182/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0601 - val_loss: 3.5442\n",
            "Epoch 183/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0588 - val_loss: 3.5394\n",
            "Epoch 184/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0572 - val_loss: 3.5469\n",
            "Epoch 185/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0560 - val_loss: 3.5536\n",
            "Epoch 186/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0546 - val_loss: 3.5595\n",
            "Epoch 187/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0538 - val_loss: 3.5586\n",
            "Epoch 188/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0526 - val_loss: 3.5580\n",
            "Epoch 189/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0514 - val_loss: 3.5686\n",
            "Epoch 190/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0503 - val_loss: 3.5668\n",
            "Epoch 191/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0495 - val_loss: 3.5763\n",
            "Epoch 192/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0484 - val_loss: 3.5772\n",
            "Epoch 193/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0477 - val_loss: 3.5856\n",
            "Epoch 194/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0475 - val_loss: 3.5991\n",
            "Epoch 195/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0463 - val_loss: 3.6045\n",
            "Epoch 196/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0454 - val_loss: 3.5887\n",
            "Epoch 197/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0444 - val_loss: 3.5987\n",
            "Epoch 198/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0440 - val_loss: 3.5951\n",
            "Epoch 199/200\n",
            "2292/2292 [==============================] - 44s 19ms/step - loss: 0.0429 - val_loss: 3.6022\n",
            "Epoch 200/200\n",
            "2292/2292 [==============================] - 43s 19ms/step - loss: 0.0420 - val_loss: 3.6033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68002d3c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "ebYs3WaQDkGN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Building Model for Prediction\n",
        "\n",
        "4.1 Build the Encoder Model to predict Encoder States**"
      ]
    },
    {
      "metadata": {
        "id": "h_CdBHv3DAAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYa1rifBDrq4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4.2 Build the Decoder Model\n",
        "Define Input for both 'h' state and 'c' state initialization\n",
        "Get RNN outputs along with h and c state\n",
        "Define Decoder Output\n",
        "Build Model**"
      ]
    },
    {
      "metadata": {
        "id": "Y-nNoxwJDm54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = Input(shape=(rnn_units,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMi5nGvPDwl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_state_input_c = Input(shape=(rnn_units,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohlUZmf7Dy4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjRvrDObD3ve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**\n",
        "Get RNN outputs, state(s)**"
      ]
    },
    {
      "metadata": {
        "id": "ABdBDj-wD0jf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = decoder_embedding(decoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gsYswQUD947",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#We will use the layer which we trained earlier\n",
        "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBPnsFZdD_wW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2foaonwqEDtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**get Decoder output**"
      ]
    },
    {
      "metadata": {
        "id": "zBCuIyk9EBjF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_outputs = decoder_dense(rnn_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KjDf4JyKEIGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build Decoder Model**"
      ]
    },
    {
      "metadata": {
        "id": "jsCDfqFVEGPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,  #Model inputs\n",
        "                     [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUEYiP-AEYya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**5.0 Predicting Output**"
      ]
    },
    {
      "metadata": {
        "id": "e2HzqTuyEcLL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build a prediction function**"
      ]
    },
    {
      "metadata": {
        "id": "OhGFEPyCEKqH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sentence(input_sequence):\n",
        "    \n",
        "    #Get the encoder state values\n",
        "    decoder_initial_states_value = encoder_model.predict(input_sequence)\n",
        "    \n",
        "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
        "    target_seq = np.zeros((1,1))    \n",
        "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
        "    \n",
        "    #flag to check if prediction should be stopped\n",
        "    stop_loop = False\n",
        "    \n",
        "    #Initialize predicted sentence\n",
        "    predicted_sentence = ''\n",
        "    \n",
        "    #start the loop\n",
        "    while not stop_loop:\n",
        "        \n",
        "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
        "                                                        decoder_initial_states_value)\n",
        "        \n",
        "        #Get the predicted output with highest probability\n",
        "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
        "        \n",
        "        #Get the predicted word from predicter integer\n",
        "        predicted_word = int_to_word_decoder[predicted_output]\n",
        "        \n",
        "        #Check if prediction should stop\n",
        "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
        "            \n",
        "            stop_loop = True\n",
        "            continue\n",
        "                    \n",
        "        #Updated predicted sentence\n",
        "        if (len(predicted_sentence) == 0):\n",
        "            predicted_sentence = predicted_word\n",
        "        else:\n",
        "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
        "            \n",
        "        #Update target_seq to be the predicted word index\n",
        "        target_seq[0][0] = predicted_output\n",
        "        \n",
        "        #Update initial states value for decoder\n",
        "        decoder_initial_states_value = [h,c]\n",
        "        \n",
        "    \n",
        "    return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOZIx0dQEhuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "e0ef45a4-0e71-4602-f1b1-c9254b60b2f1"
      },
      "cell_type": "code",
      "source": [
        "#Get a random sentence\n",
        "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
        "print(start_num)\n",
        "\n",
        "for i in range(start_num, start_num + 10):\n",
        "    input_seq = encoder_input_data[i : i+1]\n",
        "    predicted_sentence = decode_sentence(input_seq)\n",
        "    print('--------')\n",
        "    print ('Input sentence: ', encoder_text[i])\n",
        "    print ('Predicted sentence: ', predicted_sentence )"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "--------\n",
            "Input sentence:  Bring him in.\n",
            "Predicted sentence:  उसको अंदर ले आओ।\n",
            "--------\n",
            "Input sentence:  Come with us.\n",
            "Predicted sentence:  हमारे साथ आओ।\n",
            "--------\n",
            "Input sentence:  Happy Easter!\n",
            "Predicted sentence:  एसटर मुबारक हो\n",
            "--------\n",
            "Input sentence:  Has Tom left?\n",
            "Predicted sentence:  टॉम चला गया क्या\n",
            "--------\n",
            "Input sentence:  He is French.\n",
            "Predicted sentence:  वह फ़्रानसीसी है।\n",
            "--------\n",
            "Input sentence:  I am at home.\n",
            "Predicted sentence:  मैं घर पर हूँ।\n",
            "--------\n",
            "Input sentence:  I can't move.\n",
            "Predicted sentence:  मैं हिल नहीं सकता।\n",
            "--------\n",
            "Input sentence:  I don't know.\n",
            "Predicted sentence:  मुझे नहीं पता।\n",
            "--------\n",
            "Input sentence:  I don't know.\n",
            "Predicted sentence:  मुझे नहीं पता।\n",
            "--------\n",
            "Input sentence:  I have a car.\n",
            "Predicted sentence:  मैं गाड़ी चला सकता हूँ।\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}